# getRandomNumber

[![Build Status](https://travis-ci.org/benjamin-vimcar/getRandomNumber.svg?branch=master)](https://travis-ci.org/benjamin-vimcar/getRandomNumber)

An entry for the [Vimcar backend challenge](https://github.com/vimcar/backend-challenge), inspired by https://xkcd.com/221/.

# Introduction

This repository contains everything.

## Running the application

Pre-requisites are `docker` and `docker-compose`.

Run the application with `docker-compose up`. This will spin up the database and two worker servers. The two workers can be accessed at http://localhost:8080/api/v1 and http://localhost:8081/api/v1.

Go to http://localhost:8080/api/v1/ui/ in your browser to see the API documentation. This is a rendered version of the OpenAPI v2 spec located at `api.yaml`. You can use this to try out using the API without having to break out curl.

***WARNING: you will need to add 'Bearer ' to the start of the `Authorization` header. The UI does not do this for you.***

## Exploring the code

The API is defined in OpenAPI v2. The file is at `api.yaml`.

The interesting code is all in `server/swagger_server`. This is based off an autogenerated integration with connexion. The autogeneration was done using http://editor2.swagger.io/.

### Business logic

The business logic is all in `server/swagger_server/get_random_number/backend.py`. We have a `User` class that defines how users can be created and how they then behave. We also have our single resource: `get_random_number`.

### Authentication

Users have passwords (currently stored insecurely - see the 'Outstanding work' section below). Using the login endpoint, they can obtain a JWT that they can provide on subsequent requests to access protected resources.

The spec suggests that we want to use some sort of token-based authentication system, so that a user needs only login once, and then just needs to present the secret token we provide them to access protected resources.

I'm not familiar with this sort of authentication. A quick search suggests that JSON web tokens appears to be the de-facto standard here, so that's what I've used.

A search of https://jwt.io/ and Pypi reveals several packages that handle JWT. I don't have very long for the evaluation, so I'm going to try and use PyJWT - seemingly the most popular package, and both post-v1 and stagged as ready for production usage.

Unfortunately, Connexion only supports OpenAPI v2, which does not have native JWT support.

I think I can also use a JWT to conveniently produce the e-mail confirmation token. 

### Server framework

[Connexion](https://github.com/zalando/connexion) is a Flask-based server framework that provides automatic endpoint validation. I am quite familiar with it, so chose it to speed up development.

### Database

This need not be very complex. For a user database, one of the common relational databases (e.g. MySQL, postgres) seems likely to be sufficient. User operations seem unlikely to cause significant traffic. I've gone for MySQL as that was the first one I was able to get a working installed Python library for.

If we were to scale, the resources we provide seem more likely to prove bottlenecks. There exist techniques for dealing with this - e.g. CDNs, distributed eventually-consistent databases.

### Deployment

I am quite familiar with docker and docker-compose, and the connexion autogen sets up a Dockerfile. Hence, this choice was obvious to me.

I've added a second worker to the docker-compose definition. This should act as a proof-of-concept that the workers are fully independent and sideways-scalable.

### Tests

The pre-requisite is `tox`.

Run the tests by running `tox`. This will run the UTs, integration tests, and Flake 8. Travis also runs these set of tests.

The UTs may be found in `server/swagger_server/test/test_get_random_number.py`. This is a set of fast, lightweight tests that provide reasonably comprehensive coverage of the core `backend` module. Thus, these tests verify our business logic. 

Integration tests may be found in `server/swagger_server/test/test_default_controller.py`. This is a set of slightly heavier-weight tests that use the connexion test mechanism to verify the integration of our business logic with connexion in various mainline cases.

We lack automated tests for the MySQL integration. We also lack automated end-to-end tests. I ran out of time, so tested these manually.

# Outstanding work

There is plenty of work outstanding that I haven't had time to do.

## Necessary

* Stop storing passwords. Instead, we must store sensibly-hashed passwords (with unique salts). We can't really pretend to be secure until this is done. There exist Python libraries that make this a solved problem.
* [Add HTTPS support](https://github.com/zalando/connexion#https-support)
* Use actual secrets instead of our fake 'secrets' for authenticating users and confirmation tokens. At a basic level, this could just be a sufficiently random string that we share via environment variables. If we wanted to be more complex, we could probably use something like Vault integration.
* Connect to the database securely. Despite its name, `super_secret_mysql_root_password` is not a sensible root password (and we shouldn't be connecting as root anyway).

## Highly desirable

* I have a strong suspicion that we aren't tidying up our MySQL connections on application termination. Connexion exposes a decorator that allows us to run code at application shutdown. We could use that to close the MySQL handler cleanly.
* Send users e-mails rather than printing a log asking the sysadmin to send an e-mail.
* Add a timeout to our JWTs.
* [Disable the UI console.](https://github.com/zalando/connexion#the-swagger-ui-console)
* [Stop using the dev server](http://flask.pocoo.org/docs/1.0/deploying/)
* Start using prepared statements to talk to MySQL (which should have the convenient side-effect of preventing SQL injection, which we are currently vulnerable to).

## Optional

* The random number returned by `get_random_number` uses the random number from XKCD. We have no guarantees that a fair dice was used. We should obtain a dice and generate our own random number.
* Setup a load balancer and docker swarm/kubernetes/etc integration so that we can be fully sideways scaling (at least in the application).
